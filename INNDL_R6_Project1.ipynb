{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "### Problem:\n",
    "Given a Bank customer, can we build a classifier which can determine whether they will leave or\n",
    "not using Neural networks?\n",
    "\n",
    "Link to the Kaggle project site:\n",
    "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    "Case file: bank.csv\n",
    "\n",
    "The points distribution for this case is as follows:\n",
    "1. Read the dataset in a new python notebook.\n",
    "2. Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "3. Distinguish the feature and target set (2.5 points)\n",
    "4. Divide the data set into Train and test sets\n",
    "5. Normalize the train and test data (2.5 points)\n",
    "6. Initialize &amp; build the model (10 points)\n",
    "7. Optimize the model (5 points)\n",
    "9. Predict the results using 0.5 as a threshold (5 points)\n",
    "10. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbvI8LqlQlCl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPW-a-qYQlCp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74cQBsi5QlCw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Read the dataset in a new python notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('Data/bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        False\n",
       "Geography          False\n",
       "Gender             False\n",
       "Age                False\n",
       "Tenure             False\n",
       "Balance            False\n",
       "NumOfProducts      False\n",
       "HasCrCard          False\n",
       "IsActiveMember     False\n",
       "EstimatedSalary    False\n",
       "Exited             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        False\n",
       "Geography          False\n",
       "Gender             False\n",
       "Age                False\n",
       "Tenure             False\n",
       "Balance            False\n",
       "NumOfProducts      False\n",
       "HasCrCard          False\n",
       "IsActiveMember     False\n",
       "EstimatedSalary    False\n",
       "Exited             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distinguish the feature and target set (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(target.values.astype('float32'))\n",
    "X = data.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalize the train and test data (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 13), (3000,), (3000, 13), (3000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_test.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test data is already normalized before creating the tensor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Initialize & build the model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Clear the session before building the model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(30, input_dim=13, activation='relu'),\n",
    "        tf.keras.layers.Dense(40, input_dim=30, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.25),\n",
    "        #tf.keras.layers.Dense(60, input_dim=40, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, input_dim=40, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    #adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, amsgrad=True)\n",
    "    #sgd = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.5, nesterov=True)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Optimize the model (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various techniques have been tried to improve the accuracy of the NN model:\n",
    "- Adding more hidden layers\n",
    "- Adding more neurons\n",
    "- Adding Dropout layer\n",
    "- Changing Optimizer adam, sgd\n",
    "- Changing parameters: learning rate, momentum, netrove\n",
    "- Changing metrics: accuracy, rmse, mae\n",
    "- Changing batchsize\n",
    "- Changing epoch size\n",
    "- Also using KerasClassifier and Stratified KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First checking if KFold can give higher accuracy; If not, procedding with the simple approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 85.89%\n",
      "Mean Standard Deviation: 0.50%\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=False)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X.values, y, cv=kfold)\n",
    "print(\"Mean Accuracy: %.2f%%\" % (results.mean()*100))\n",
    "print(\"Mean Standard Deviation: %.2f%%\" % (results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 3s 381us/sample - loss: 0.5110 - accuracy: 0.7540 - val_loss: 0.4279 - val_accuracy: 0.8090\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.4324 - accuracy: 0.8133 - val_loss: 0.4023 - val_accuracy: 0.8277\n",
      "Epoch 3/50\n",
      "7000/7000 [==============================] - 1s 101us/sample - loss: 0.4053 - accuracy: 0.8291 - val_loss: 0.3702 - val_accuracy: 0.8457\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 1s 103us/sample - loss: 0.3776 - accuracy: 0.8411 - val_loss: 0.3479 - val_accuracy: 0.8573\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 1s 107us/sample - loss: 0.3649 - accuracy: 0.8460 - val_loss: 0.3448 - val_accuracy: 0.8617\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 1s 124us/sample - loss: 0.3611 - accuracy: 0.8493 - val_loss: 0.3436 - val_accuracy: 0.8627\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3571 - accuracy: 0.8483 - val_loss: 0.3419 - val_accuracy: 0.8633\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 1s 105us/sample - loss: 0.3515 - accuracy: 0.8527 - val_loss: 0.3363 - val_accuracy: 0.8663\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 1s 102us/sample - loss: 0.3546 - accuracy: 0.8503 - val_loss: 0.3369 - val_accuracy: 0.8660\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 1s 105us/sample - loss: 0.3526 - accuracy: 0.8520 - val_loss: 0.3373 - val_accuracy: 0.8650\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3502 - accuracy: 0.8554 - val_loss: 0.3378 - val_accuracy: 0.8640\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3501 - accuracy: 0.8523 - val_loss: 0.3344 - val_accuracy: 0.8657\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 1s 122us/sample - loss: 0.3496 - accuracy: 0.8527 - val_loss: 0.3317 - val_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 1s 131us/sample - loss: 0.3464 - accuracy: 0.8527 - val_loss: 0.3328 - val_accuracy: 0.8650\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 1s 126us/sample - loss: 0.3453 - accuracy: 0.8571 - val_loss: 0.3333 - val_accuracy: 0.8670\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3432 - accuracy: 0.8553 - val_loss: 0.3324 - val_accuracy: 0.8640\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.3416 - accuracy: 0.8574 - val_loss: 0.3321 - val_accuracy: 0.8673\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 1s 132us/sample - loss: 0.3452 - accuracy: 0.8550 - val_loss: 0.3299 - val_accuracy: 0.8687\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3430 - accuracy: 0.8553 - val_loss: 0.3321 - val_accuracy: 0.8680\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.3411 - accuracy: 0.8571 - val_loss: 0.3328 - val_accuracy: 0.8677\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3386 - accuracy: 0.8571 - val_loss: 0.3362 - val_accuracy: 0.8637\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.3415 - accuracy: 0.8590 - val_loss: 0.3354 - val_accuracy: 0.8660\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 1s 126us/sample - loss: 0.3410 - accuracy: 0.8559 - val_loss: 0.3329 - val_accuracy: 0.8667\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 1s 125us/sample - loss: 0.3388 - accuracy: 0.8587 - val_loss: 0.3352 - val_accuracy: 0.8637\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 1s 117us/sample - loss: 0.3373 - accuracy: 0.8607 - val_loss: 0.3364 - val_accuracy: 0.8623\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 1s 124us/sample - loss: 0.3404 - accuracy: 0.8546 - val_loss: 0.3339 - val_accuracy: 0.8647\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 1s 122us/sample - loss: 0.3409 - accuracy: 0.8530 - val_loss: 0.3298 - val_accuracy: 0.8673\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3380 - accuracy: 0.8564 - val_loss: 0.3310 - val_accuracy: 0.8683\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 1s 126us/sample - loss: 0.3386 - accuracy: 0.8573 - val_loss: 0.3309 - val_accuracy: 0.8680\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 1s 118us/sample - loss: 0.3399 - accuracy: 0.8584 - val_loss: 0.3314 - val_accuracy: 0.8677\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 1s 122us/sample - loss: 0.3362 - accuracy: 0.8594 - val_loss: 0.3341 - val_accuracy: 0.8680\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 1s 118us/sample - loss: 0.3399 - accuracy: 0.8566 - val_loss: 0.3356 - val_accuracy: 0.8627\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3322 - accuracy: 0.8640 - val_loss: 0.3321 - val_accuracy: 0.8653\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3337 - accuracy: 0.8566 - val_loss: 0.3333 - val_accuracy: 0.8613\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3341 - accuracy: 0.8589 - val_loss: 0.3348 - val_accuracy: 0.8680\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3277 - accuracy: 0.8661 - val_loss: 0.3381 - val_accuracy: 0.8623\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.3345 - accuracy: 0.8590 - val_loss: 0.3334 - val_accuracy: 0.8637\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.3299 - accuracy: 0.8617 - val_loss: 0.3371 - val_accuracy: 0.8677\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.3311 - accuracy: 0.8607 - val_loss: 0.3359 - val_accuracy: 0.8667\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 1s 119us/sample - loss: 0.3331 - accuracy: 0.8620 - val_loss: 0.3351 - val_accuracy: 0.8653\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 1s 129us/sample - loss: 0.3321 - accuracy: 0.8610 - val_loss: 0.3374 - val_accuracy: 0.8657\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 1s 120us/sample - loss: 0.3319 - accuracy: 0.8616 - val_loss: 0.3357 - val_accuracy: 0.8680\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3299 - accuracy: 0.8647 - val_loss: 0.3354 - val_accuracy: 0.8647\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3321 - accuracy: 0.8601 - val_loss: 0.3368 - val_accuracy: 0.8660\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3279 - accuracy: 0.8606 - val_loss: 0.3385 - val_accuracy: 0.8660\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3275 - accuracy: 0.8607 - val_loss: 0.3352 - val_accuracy: 0.8660\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3284 - accuracy: 0.8606 - val_loss: 0.3425 - val_accuracy: 0.8677\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3296 - accuracy: 0.8607 - val_loss: 0.3425 - val_accuracy: 0.8657\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 1s 108us/sample - loss: 0.3273 - accuracy: 0.8604 - val_loss: 0.3380 - val_accuracy: 0.8667\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3286 - accuracy: 0.8606 - val_loss: 0.3398 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2abcabf5a88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the  model with the given dataset\n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predict the results using 0.5 as a threshold (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(data=y_pred, columns=['Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.loc[y_pred_df.Prob >= 0.5, 'Prob'] = 1\n",
    "y_pred_df.loc[y_pred_df.Prob < 0.5, 'Prob'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the model: 86.50%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of the model: %.2f%%' % (accuracy_score(y_test, y_pred_df.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2300,  116],\n",
       "       [ 289,  295]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By employing various techniques of NN model improvement, the best accuracy I got is between 86 and 87%. I couldn't find a better model than this one.\n",
    "### The model fine tuning is an exploratory exercise and we may find better parameters by experimenting more."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_R7_ExternalLab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
